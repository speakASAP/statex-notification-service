#!/bin/bash

# StateX Free AI Services Setup Script
# This script sets up free AI services for testing

echo "ğŸ†“ Setting up Free AI Services for StateX..."

# Check if Ollama is installed
if ! command -v ollama &> /dev/null; then
    echo "ğŸ“¥ Installing Ollama..."
    
    # Detect OS and install Ollama
    if [[ "$OSTYPE" == "darwin"* ]]; then
        # macOS
        echo "ğŸ Installing Ollama for macOS..."
        curl -fsSL https://ollama.ai/install.sh | sh
    elif [[ "$OSTYPE" == "linux-gnu"* ]]; then
        # Linux
        echo "ğŸ§ Installing Ollama for Linux..."
        curl -fsSL https://ollama.ai/install.sh | sh
    else
        echo "âŒ Unsupported OS. Please install Ollama manually from https://ollama.ai"
        exit 1
    fi
else
    echo "âœ… Ollama is already installed"
fi

# Start Ollama service
echo "ğŸš€ Starting Ollama service..."
ollama serve &
OLLAMA_PID=$!

# Wait for Ollama to start
echo "â³ Waiting for Ollama to start..."
sleep 5

# Download free models
echo "ğŸ“¥ Downloading free AI models..."

# Llama 2 7B (Good for general text generation)
echo "ğŸ“¥ Downloading Llama 2 7B..."
ollama pull llama2:7b

# Mistral 7B (Good for code and analysis)
echo "ğŸ“¥ Downloading Mistral 7B..."
ollama pull mistral:7b

# CodeLlama 7B (Good for technical analysis)
echo "ğŸ“¥ Downloading CodeLlama 7B..."
ollama pull codellama:7b

echo ""
echo "ğŸ‰ Free AI Services Setup Complete!"
echo ""
echo "ğŸ“‹ Available Models:"
echo "  â€¢ llama2:7b - General text generation"
echo "  â€¢ mistral:7b - Code and analysis"
echo "  â€¢ codellama:7b - Technical analysis"
echo ""
echo "ğŸ”§ To use these models:"
echo "  â€¢ Test: ollama run llama2:7b 'Hello, how are you?'"
echo "  â€¢ List models: ollama list"
echo "  â€¢ Stop service: kill $OLLAMA_PID"
echo ""
echo "ğŸš€ Now you can run: python3 test_workflow_free_ai.py --demo"
